{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f768f51ff419d",
   "metadata": {},
   "source": [
    "**Abhina Premachandran Bindu**\n",
    "\n",
    "**May 22 2024**\n",
    "\n",
    "# Preprocessing the dataset using Gensim Library\n",
    "  <p> The goal of this notebook is to explain the working of the classifier. A Decision Tree classifier is used to fit and train on the word embeddings. To understand the working of the classifier, shap plots are used for individual test data. Further, the feature importance is found using the feature_importances_ attribute of the DecisionTree classifier.</p>\n",
    "  <p>This is similar to the previos notebook except that here the analysis is done by removing 'reuters' from the data due to its redundancy in providingnew insights. </p>\n",
    "  \n",
    "  \n",
    "## Loading and initial cleaning of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:12.339618Z",
     "start_time": "2024-04-15T19:13:35.985792Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing nlp\n",
    "import nltk\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# importing sklearn for model building\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# importing shap\n",
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c11d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:18.560168Z",
     "start_time": "2024-04-15T19:14:12.350041Z"
    }
   },
   "outputs": [],
   "source": [
    "# combining the two separate csv files with fake and real data to a single dataframe \n",
    "# df1 --> Fake , df2 --> Real\n",
    "df1 = pd.read_csv(input(\"Enter the file path for the fake dataset\"))\n",
    "df2 = pd.read_csv(input(\"Enter the file path for the real dataset\"))\n",
    "\n",
    "# adding the labels Fake --> 0 and Real --> 1\n",
    "df1['target'] = 0\n",
    "df2['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a410d05af240b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:18.560168Z",
     "start_time": "2024-04-15T19:14:12.350041Z"
    }
   },
   "outputs": [],
   "source": [
    "# combining the dataframes\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "# shuffling the indices\n",
    "data = combined_df.sample(frac=1, random_state=42)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "data.to_csv('fake_real_final.csv', index = False)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f953265c8e649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:18.726669Z",
     "start_time": "2024-04-15T19:14:18.561643Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa469c0361198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:18.753125Z",
     "start_time": "2024-04-15T19:14:18.727513Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d38d8d7566387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:18.792637Z",
     "start_time": "2024-04-15T19:14:18.783529Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking the value counts of 'target' to check for data imbalance\n",
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc56e418debe90",
   "metadata": {},
   "source": [
    " Since the number of Fake and True classes are almost same, there is no class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bca5964e15350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:18.799744Z",
     "start_time": "2024-04-15T19:14:18.794324Z"
    }
   },
   "outputs": [],
   "source": [
    "data.subject.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b0b5df254691f",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e1180fd44141a",
   "metadata": {},
   "source": [
    "### cleaning and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b35f4ab0e8b04c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:37.379701Z",
     "start_time": "2024-04-15T19:14:19.132821Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "stop_words = set(stopwords.words('english'))\n",
    "remove_words = {'reuters', 'reuter'}\n",
    "def clean_text(text):\n",
    "    # Tokenizing\n",
    "    tokens = word_tokenize(text)\n",
    "    # removing non-alphabetical characters and stopwords\n",
    "    cleaned_tokens = [re.sub(r'[^a-zA-Z ]', '', text).lower() for text in tokens if text.lower() not in stop_words]\n",
    "    cleaned_tokens = [token for token in cleaned_tokens if token not in set(string.punctuation)]\n",
    "    # removing the news media name - 'reuters' from the text\n",
    "    cleaned_tokens = [token for token in cleaned_tokens if token not in remove_words]\n",
    "    # Lemmatizing the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    porter = PorterStemmer()\n",
    "    cleaned_text = \" \".join(porter.stem(token) for token in processed_text.split())\n",
    "    return cleaned_text\n",
    "\n",
    "# Applying the function across the DataFrame\n",
    "data['cleaned_text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f613c87041eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:14:37.501071Z",
     "start_time": "2024-04-15T19:14:37.420737Z"
    }
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5766467e",
   "metadata": {},
   "source": [
    "## Classifying the data using DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6dc81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining X and y arrays\n",
    "# X = word_vectors\n",
    "X = data['cleaned_text'].values\n",
    "y = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0db061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the Tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_vec = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38386d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the classification model\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cd9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the test values\n",
    "y_pred = tree_clf.predict(X_test_vec)\n",
    "# printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0308f99",
   "metadata": {},
   "source": [
    "## Understanding the classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68bf5e0",
   "metadata": {},
   "source": [
    "### 1. Using Shap for Decision Tree clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84197dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the feature names from tfidf vectorizer\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "# getting the shap values\n",
    "explainer = shap.Explainer(tree_clf, X_train_vec, feature_names=feature_names)\n",
    "shap_values = explainer(X_test_vec)\n",
    "print(shap_values.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ce7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the shap waterfall plot for the 7th test data\n",
    "shap.initjs()\n",
    "\n",
    "ind = 6\n",
    "print(X_test[ind])\n",
    "\n",
    "shap.plots.waterfall(shap_values[ind,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4585be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the shap waterfall plot for the 11th test data\n",
    "shap.initjs()\n",
    "\n",
    "ind = 10\n",
    "print(X_test[ind])\n",
    "\n",
    "shap.plots.waterfall(shap_values[ind,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the shap waterfall plot for the 201st test data\n",
    "shap.initjs()\n",
    "\n",
    "ind = 1\n",
    "print(X_test[ind])\n",
    "\n",
    "shap.plots.waterfall(shap_values[ind,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f306f",
   "metadata": {},
   "source": [
    "  From the three waterfall plots above, it is clear that the model uses the word 'reuter' as the primary indicator of whether a text classifies as fake or real. If the shap value of 'reuter' is greater than 0, it classifies the text as real and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values[:,:,1], X_test_vec, feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9584ba",
   "metadata": {},
   "source": [
    "### 2. Using Decision Tree classifier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330990e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = [\"Fake\", \"Real\"]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "vis = tree.plot_tree(\n",
    "    tree_clf,\n",
    "    class_names=class_names,\n",
    "    feature_names = vectorizer.get_feature_names_out(),\n",
    "    max_depth=3,\n",
    "    fontsize=9,\n",
    "    proportion=True,\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4bb58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_importance = tree_clf.feature_importances_\n",
    "inds = np.argsort(np.abs(feature_importance))[::-1]\n",
    "top_10_inds = inds[:10]\n",
    "fig, ax = plt.subplots()\n",
    "rank = np.arange(10)\n",
    "ax.bar(rank, feature_importance[top_10_inds])\n",
    "ax.set_xticks(rank)\n",
    "ax.set_xticklabels(np.array(feature_names)[top_10_inds], rotation=45, ha='right')\n",
    "ax.set_ylabel(\"Top 10 Important Features and their ranks\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51538834",
   "metadata": {},
   "source": [
    "  The above tree visualization of the classifier indicates that the classifier uses 'reuter' feature as one of the main feature to decide whether the text is fake or real. In the next level, 'zika' and 'wiretv' are used to split the data into the respective classes based on certain threshold values for the features. The bar chart on the feature importance also indicates that the 'reuter' feature have a huge significance in influencing the model decision compared to other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47768625",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------\n",
    "Testing the python libraries for the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_explainability_shap as shap_model\n",
    "import decision_tree_visualization as dt_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_model.plot_waterfall(shap_values, 6, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_model.plot_waterfall(shap_values, 10, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50285498",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_model.plot_summary(shap_values, X_test_vec, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cedbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Fake\", \"Real\"]\n",
    "dt_visual.plot_tree_and_feature_importance(tree_clf, vectorizer, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab0247",
   "metadata": {},
   "source": [
    "From the three waterfall plots above, an idea on the features that the model relies on class prediction is evident. The 6th indexed test data shows that the features 'said','via', and 'washington' predicts the data as real. for the 10th indexed test value, the features 'washington' and 'breitbart' votes in more weight for the data to be in the fake class. These plots indicates how the model performs in the local level.\n",
    "The above summary plot picturizes how the model works in a global scale. It shows that 'said' and 'via' are two important word features that the model heavily relies on deciding which class a data belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13873508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
