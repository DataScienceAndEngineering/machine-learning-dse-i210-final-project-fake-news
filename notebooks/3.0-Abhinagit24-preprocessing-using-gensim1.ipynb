{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f768f51ff419d",
   "metadata": {},
   "source": [
    "**Abhina Premachandran Bindu**\n",
    "# Preprocessing the dataset using Gensim Library\n",
    "## Loading and initial cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:03.168460Z",
     "start_time": "2024-04-22T16:59:56.406932Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import gensim.downloader as api\n",
    "# wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a410d05af240b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:06.456331Z",
     "start_time": "2024-04-22T17:00:03.169731Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing the data\n",
    "data = pd.read_csv(input('Enter the file path for the csv file:'))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f953265c8e649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:07.399726Z",
     "start_time": "2024-04-22T17:00:07.392684Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa469c0361198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:07.977642Z",
     "start_time": "2024-04-22T17:00:07.962025Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5d09acbbb714",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:08.387678Z",
     "start_time": "2024-04-22T17:00:08.376109Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping the na values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d0576792227a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:09.187986Z",
     "start_time": "2024-04-22T17:00:09.178909Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping the redundant 'Unnamed: 0' column\n",
    "data.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d38d8d7566387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:09.374938Z",
     "start_time": "2024-04-22T17:00:09.368576Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking the value counts of 'target' to check for data imbalance\n",
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc56e418debe90",
   "metadata": {},
   "source": [
    " Since the number of Fake and True classes are almost same, there is no class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bca5964e15350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:10.486439Z",
     "start_time": "2024-04-22T17:00:10.477491Z"
    }
   },
   "outputs": [],
   "source": [
    "data.subject.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f11dd8df7a632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:12.205155Z",
     "start_time": "2024-04-22T17:00:11.999022Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the distribution of subjects\n",
    "plt.hist(data['subject'], bins=len(data.subject.unique()), align = 'mid', edgecolor='black')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Subjects')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b0b5df254691f",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22994fa5cd64e4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:13.951223Z",
     "start_time": "2024-04-22T17:00:13.921085Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoding the class labels to numerical - Real:1 and Fake:0\n",
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(data['target']))}\n",
    "data['target'] = data['target'].map(class_mapping)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b35f4ab0e8b04c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:28.685653Z",
     "start_time": "2024-04-22T17:00:16.612222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the function across the DataFrame\n",
    "data['cleaned_text'] = data['text'].apply(gensim.utils.simple_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f613c87041eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:28.698937Z",
     "start_time": "2024-04-22T17:00:28.689335Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f629a1e0649970",
   "metadata": {},
   "source": [
    "## Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5fce8963c290d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:44:17.487998Z",
     "start_time": "2024-04-22T17:42:22.968175Z"
    }
   },
   "outputs": [],
   "source": [
    "# using the Counter function to get the count of words to find the most frequent words \n",
    "from collections import Counter\n",
    "all_real_words = []\n",
    "all_fake_words = []\n",
    "for i,text in enumerate(data['cleaned_text']):\n",
    "    for word in text:\n",
    "        if data.iloc[i,2] == 1:\n",
    "            all_real_words.append(word)\n",
    "        else:\n",
    "            all_fake_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e23ca386b6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_real = Counter(all_real_words)\n",
    "word_counts_fake = Counter(all_fake_words)\n",
    "\n",
    "most_common_words_real = word_counts_real.most_common(20)\n",
    "most_common_words_fake = word_counts_fake.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b558cc0e0974b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining separate new dataframes for most common words in the rela and fake text classes\n",
    "common_words_realdf = pd.DataFrame(most_common_words_real, columns=['Word', 'Frequency'])\n",
    "common_words_fakedf = pd.DataFrame(most_common_words_fake, columns=['Word', 'Frequency'])\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Plot the most frequent words in real news on the first subplot\n",
    "axs[0].bar(common_words_realdf['Word'], common_words_realdf['Frequency'], color = 'blue')\n",
    "axs[0].set_xlabel('Word')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "axs[0].set_title('Most Frequent Words in Real News')\n",
    "axs[0].tick_params(axis='x', rotation=45)  # Rotate x-axis labels for readability\n",
    "axs[0].legend(['Real News'])\n",
    "\n",
    "# Plot the most frequent words in fake news on the second subplot\n",
    "axs[1].bar(common_words_fakedf['Word'], common_words_fakedf['Frequency'], color = 'red')\n",
    "axs[1].set_xlabel('Word')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "axs[1].set_title('Most Frequent Words in Fake News')\n",
    "axs[1].tick_params(axis='x', rotation=45)  \n",
    "axs[1].legend(['Fake News'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1529ac2",
   "metadata": {},
   "source": [
    "## Building, training and using the gensim word2vect model for getting the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b672d749b5e307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:00:33.059974Z",
     "start_time": "2024-04-22T17:00:28.700007Z"
    }
   },
   "outputs": [],
   "source": [
    "# building the word2vec model\n",
    "model = gensim.models.Word2Vec(\n",
    "    window = 6,\n",
    "    min_count = 1,\n",
    "    workers = 4\n",
    ")\n",
    "model.build_vocab(data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f44e4c18b3166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:01:15.079286Z",
     "start_time": "2024-04-22T17:00:33.063032Z"
    }
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "model.train(data['cleaned_text'], total_examples=model.corpus_count, epochs=5)\n",
    "\n",
    "# saving the model\n",
    "model.save(\"word2vec/word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f46ff7246eda5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:01:15.087410Z",
     "start_time": "2024-04-22T17:01:15.081384Z"
    }
   },
   "outputs": [],
   "source": [
    "model.wv.index_to_key[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd66cead82b8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:01:15.092305Z",
     "start_time": "2024-04-22T17:01:15.088668Z"
    }
   },
   "outputs": [],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebf91701154dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:01:31.699238Z",
     "start_time": "2024-04-22T17:01:15.093982Z"
    }
   },
   "outputs": [],
   "source": [
    "# a function for finding the average of the word vectors \n",
    "def get_average_word2vec_vector(text, model, word_dim):\n",
    "  vec = np.zeros((word_dim,))  \n",
    "  count = 0\n",
    "  for word in text:\n",
    "    if word in model.wv:  \n",
    "      vec += model.wv[word]\n",
    "      count += 1\n",
    "  if count != 0:\n",
    "    vec /= count  \n",
    "  return vec\n",
    "\n",
    "# Get word dimensions from the model\n",
    "word_dim = model.vector_size\n",
    "\n",
    "# Apply the function to each cleaned_text\n",
    "word_vectors = [get_average_word2vec_vector(text, model, word_dim) for text in data['cleaned_text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e3c485bc59c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:01:31.709888Z",
     "start_time": "2024-04-22T17:01:31.701562Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding the word vectors to the data\n",
    "data['word_vectors'] = word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cc3fca3edfe39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:02:15.811086Z",
     "start_time": "2024-04-22T17:02:15.795481Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f492400931c593c5",
   "metadata": {},
   "source": [
    "## Classifying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78df15071a62378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:04:30.860678Z",
     "start_time": "2024-04-22T17:04:30.020940Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries for model building\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d63d09a35b8e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:04:33.656867Z",
     "start_time": "2024-04-22T17:04:33.653901Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining X and y \n",
    "X = word_vectors\n",
    "y = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556f22920bc2336",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:06:58.215927Z",
     "start_time": "2024-04-22T17:06:58.190342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587172b0dedee0a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:07:00.855224Z",
     "start_time": "2024-04-22T17:07:00.778698Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshaping the input values for classifying\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d =  np.stack(X_test)\n",
    "X_train_2d.shape , X_test_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bad347a4fe25e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T17:09:33.240494Z",
     "start_time": "2024-04-22T17:07:19.410702Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# defining the model, fitting and predicting value for X_test.\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "# printing the classification report for validation of the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb98bc",
   "metadata": {},
   "source": [
    " The Graident Boosting classifier classifies the text data as real or fake with an accuracy score of 96%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
