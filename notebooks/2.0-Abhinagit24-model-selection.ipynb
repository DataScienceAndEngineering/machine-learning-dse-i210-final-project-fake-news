{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f66a53480a5ffc",
   "metadata": {},
   "source": [
    "# Model Testing and Selection\n",
    "   <p>I am focusing on finding the best model that classifies the data to real and fake. For this, the ML classification algorithms: LogisticRegression,QuadraticDiscriminantAnalysis, SVC, LinearSVC, DecisionTreeClassifier, XGBoost, AdaBoost, Perceptron, KNN, GaussianNB, BaggingClassifier are being used. For faster computation, the dataset is sampled down to a size of 2000.</p>\n",
    "    <p>Further Gridsearch analysis is required to find the best parameters that results in the best models that can be fitted for training.</p>\n",
    "    \n",
    "#### Initial loading and cleaning of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b3d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path of the data file/Users/abhinapremachandran/Desktop/Spring '24 CCNY/Machine Learning/group_project_ML/fake_real_final.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
       "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>February 13, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 5, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
       "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 27, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
       "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
       "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 24, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
       "1  Trump drops Steve Bannon from National Securit...   \n",
       "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
       "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
       "4  Donald Trump heads for Scotland to reopen a go...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
       "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
       "3  On Monday, Donald Trump once again embarrassed...          News   \n",
       "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
       "\n",
       "                  date  target  \n",
       "0    February 13, 2017       0  \n",
       "1       April 5, 2017        1  \n",
       "2  September 27, 2017        1  \n",
       "3         May 22, 2017       0  \n",
       "4       June 24, 2016        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data from the downloaded csv file\n",
    "file_path = input(\"Enter the path of the data file\")\n",
    "data = pd.read_csv(file_path)\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3831ce87c3ecee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting the data frame for faster computation\n",
    "sample_size = 20000\n",
    "data_sample = data.sample(n=sample_size,random_state=22)\n",
    "\n",
    "# Tokenize and removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove non-alphabetical characters and stopwords\n",
    "    cleaned_tokens = [re.sub(r'[^a-zA-Z ]', '', text).lower() for text in tokens if text.lower() not in stop_words]\n",
    "    cleaned_tokens = [token for token in cleaned_tokens if ((token not in  set(string.punctuation)))]\n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    #stem the tokens\n",
    "    porter = PorterStemmer()\n",
    "    cleaned_text = \" \".join(porter.stem(token) for token in processed_text.split())\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function across the DataFrame\n",
    "data_sample['cleaned_text'] = data_sample['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d336e28741eeda94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the X and y \n",
    "X = data_sample['cleaned_text'].values\n",
    "y = data_sample['target'].values\n",
    "# splitting data to train-test split\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=22)\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8920c1cefeddda",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c663c82f8cbbe5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the classification algorithms\n",
    "\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29a7dafedf3300bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling all the ML classification algorithms imported above\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "lr_solver1 = LogisticRegression(C=100.0, solver='lbfgs', multi_class='ovr')\n",
    "lr_solver2 = LogisticRegression(C=100.0, solver='liblinear', multi_class='ovr')\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "svm_linear = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svm_rbf = SVC(kernel='rbf', random_state=1, gamma=0.10, C=10.0)\n",
    "linear_svc = LinearSVC(dual=\"auto\", random_state=0, tol=1e-5)\n",
    "tree_gini = DecisionTreeClassifier(criterion='gini',max_depth=4,random_state=1)\n",
    "tree_entropy = DecisionTreeClassifier(criterion='entropy',max_depth=4,random_state=1)\n",
    "abc = AdaBoostClassifier(algorithm='SAMME',n_estimators=100,learning_rate=0.1,random_state=1)\n",
    "RF = RandomForestClassifier(n_estimators=20,random_state=1,n_jobs=2)\n",
    "bag = BaggingClassifier(n_estimators=100,max_samples=1.0,max_features=1.0,bootstrap=True,bootstrap_features=False,n_jobs=1,random_state=1)\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.01,max_depth=4, random_state=1,use_label_encoder=False)\n",
    "mlp = MLPClassifier(alpha=1, max_iter=100, random_state=42)\n",
    "GPC = GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc08e9ef31737866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for perceptron: 0.985\n",
      "Test Accuracy for perceptron: 0.988\n",
      "----------------------------------------------\n",
      "Validation Accuracy for Log Reg lbfgs: 0.988\n",
      "Test Accuracy for Log Reg lbfgs: 0.992\n",
      "----------------------------------------------\n",
      "Validation Accuracy for Log Reg liblinear: 0.991\n",
      "Test Accuracy for Log Reg liblinear: 0.993\n",
      "----------------------------------------------\n",
      "Validation Accuracy for KNN: 0.640\n",
      "Test Accuracy for KNN: 0.619\n",
      "----------------------------------------------\n",
      "Validation Accuracy for Linear kernel svm: 0.989\n",
      "Test Accuracy for Linear kernel svm: 0.991\n",
      "----------------------------------------------\n",
      "Validation Accuracy for RBF kernel svm: 0.992\n",
      "Test Accuracy for RBF kernel svm: 0.993\n",
      "----------------------------------------------\n",
      "Validation Accuracy for Linear SVC: 0.991\n",
      "Test Accuracy for Linear SVC: 0.992\n",
      "----------------------------------------------\n",
      "Validation Accuracy for Decision Tree gini: 0.993\n",
      "Test Accuracy for Decision Tree gini: 0.994\n",
      "----------------------------------------------\n",
      "Validation Accuracy for Decision Tree entropy: 0.994\n",
      "Test Accuracy for Decision Tree entropy: 0.994\n",
      "----------------------------------------------\n",
      "Validation Accuracy for AdaBoost: 0.992\n",
      "Test Accuracy for AdaBoost: 0.993\n",
      "----------------------------------------------\n",
      "Validation Accuracy for RandomForest: 0.972\n",
      "Test Accuracy for RandomForest: 0.972\n",
      "----------------------------------------------\n",
      "Validation Accuracy for Bagging Clf: 0.996\n",
      "Test Accuracy for Bagging Clf: 0.995\n",
      "----------------------------------------------\n",
      "Validation Accuracy for xgb: 0.994\n",
      "Test Accuracy for xgb: 0.996\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# defining a dictionary containing all the algorithms and their names\n",
    "clf_dict = {'perceptron':ppn, 'Log Reg lbfgs':lr_solver1, 'Log Reg liblinear':lr_solver2, 'KNN':knn, 'Linear kernel svm':svm_linear, 'RBF kernel svm':svm_rbf, 'Linear SVC':linear_svc, 'Decision Tree gini':tree_gini,'Decision Tree entropy':tree_entropy, 'AdaBoost':abc, 'RandomForest':RF,'Bagging Clf':bag,'xgb':xgb_model}\n",
    "\n",
    "# for clf_name, clf in clf_dict.items():\n",
    "#     clf_tfidf = Pipeline([\n",
    "#     ('vect',tfidf),\n",
    "#     (clf_name,clf)])\n",
    "#     clf_tfidf.fit(X_train,y_train)\n",
    "#     print(f'Test Accuracy for {clf_name}: {clf_tfidf.score(X_test, y_test):.3f}')\n",
    "#     print('----------------------------------------------')\n",
    "\n",
    "for clf_name, clf in clf_dict.items():\n",
    "    clf_pipeline = Pipeline([\n",
    "        ('vect', tfidf),\n",
    "        (clf_name, clf)\n",
    "    ])\n",
    "    clf_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_accuracy = clf_pipeline.score(X_val, y_val)\n",
    "    print(f'Validation Accuracy for {clf_name}: {val_accuracy:.3f}')\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_accuracy = clf_pipeline.score(X_test, y_test)\n",
    "    print(f'Test Accuracy for {clf_name}: {test_accuracy:.3f}')\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "#'GaussianNB':nb,\n",
    "#'Quadratic Discriminant Analysis':QDA,\n",
    "#,'MLP':mlp,'Gaussian PC':GPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b03af9a7c8b813",
   "metadata": {},
   "source": [
    " From the validation and test accuracies of the models used, Log Reg liblinear, svm with RBF kernel, svm with linear kernel, Decision Tree, Adaboost, Bagging classifier, and xgb are some of the best models to use. KNN is the worst for our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e48a558a6da43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
